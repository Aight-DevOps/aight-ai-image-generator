#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MemoryManager - ã‚¦ãƒ«ãƒˆãƒ©ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
- check_memory_usage: VRAM ä½¿ç”¨é‡ç›£è¦–
- perform_aggressive_memory_cleanup: ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- escalate_memory_adjustment: æ®µéšçš„ãƒ¡ãƒ¢ãƒªèª¿æ•´
- execute_with_ultra_memory_safety: ãƒ¡ãƒ¢ãƒªã‚»ãƒ¼ãƒ•å®Ÿè¡Œ
"""

import time
import gc
import torch
from common.logger import ColorLogger
from common.types import HybridGenerationError

class MemoryManager:
    """ã‚¦ãƒ«ãƒˆãƒ©ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: dict):
        self.logger = ColorLogger()
        mem_cfg = config.get('memory_management', {})
        self.enabled = mem_cfg.get('enabled', True)
        self.threshold = mem_cfg.get('threshold_percent', 70)
        self.auto_adjust = mem_cfg.get('auto_adjustment_enabled', True)
        self.cleanup_interval = mem_cfg.get('cleanup_interval', 1)

        # å¼·åŒ–è¨­å®š
        self.aggressive_cleanup = True
        self.preemptive_adjustment = True
        self.ultra_safe_mode = True
        self.max_retries = mem_cfg.get('max_memory_retries', 5)
        self.recovery_delay = mem_cfg.get('memory_recovery_delay', 10)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£åƒåº¦ãƒªã‚¹ãƒˆ
        self.fallback_resolutions = config.get('fallback_resolutions', [])
        self.current_level = -1
        # ã‚ªãƒªã‚¸ãƒŠãƒ«è§£åƒåº¦ä¿å­˜
        self.original = {
            'width': config.get('sdxl_generation', {}).get('width'),
            'height': config.get('sdxl_generation', {}).get('height')
        }

    def check_memory_usage(self, force_cleanup=False) -> bool:
        """VRAM ä½¿ç”¨é‡ã®ç›£è¦–ã¨é–¾å€¤è¶…éæ™‚å¯¾å¿œ"""
        if not torch.cuda.is_available() or not self.enabled:
            return True
        try:
            alloc = torch.cuda.memory_allocated() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            percent = (alloc/total)*100
            self.logger.print_status(f"ğŸ§  VRAMä½¿ç”¨: {alloc:.2f}GB/{total:.2f}GB ({percent:.1f}%)")
            if force_cleanup or percent > self.threshold:
                if force_cleanup:
                    self.perform_aggressive_memory_cleanup()
                else:
                    self.logger.print_warning(f"âš ï¸ VRAM {self.threshold}% è¶…é: {percent:.1f}%")
                    self.perform_aggressive_memory_cleanup()
                    if self.auto_adjust:
                        self.escalate_memory_adjustment()
                return False
            return True
        except Exception as e:
            self.logger.print_error(f"âŒ ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            return True

    def perform_aggressive_memory_cleanup(self):
        """ç©æ¥µçš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            self.logger.print_status("ğŸ§¹ ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
            if torch.cuda.is_available():
                for _ in range(3):
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    time.sleep(1)
            for _ in range(3):
                gc.collect()
                time.sleep(0.5)
            time.sleep(self.recovery_delay)
            self.logger.print_success("âœ… ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            self.logger.print_error(f"âŒ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def escalate_memory_adjustment(self) -> bool:
        """æ®µéšçš„ãƒ¡ãƒ¢ãƒªèª¿æ•´ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£åƒåº¦åˆ‡ã‚Šæ›¿ãˆï¼‰"""
        self.current_level += 1
        if self.current_level >= len(self.fallback_resolutions):
            self.logger.print_error("âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£åƒåº¦ä¸Šé™ã«åˆ°é”")
            return False
        fb = self.fallback_resolutions[self.current_level]
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        # è¨­å®šåæ˜ ã¯å¤–éƒ¨ã§å¯¾å¿œ
        self.logger.print_warning(f"ğŸ“‰ è§£åƒåº¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é©ç”¨: {fb['width']}x{fb['height']}")
        return True

    def execute_with_ultra_memory_safety(self, func, name: str, max_retries: int=None):
        """
        ã‚¦ãƒ«ãƒˆãƒ©ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ä»˜ãå®Ÿè¡Œ
        Args:
            func: å®Ÿè¡Œé–¢æ•°
            name: å‡¦ç†å
        """
        if max_retries is None:
            max_retries = self.max_retries
        for attempt in range(max_retries):
            try:
                if self.ultra_safe_mode:
                    self.logger.print_status(f"ğŸ›¡ï¸ äº‹å‰ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯: {name}")
                    self.check_memory_usage(force_cleanup=True)
                result = func()
                self.perform_aggressive_memory_cleanup()
                return result
            except RuntimeError as e:
                if "CUDA out of memory" in str(e) and attempt < max_retries-1:
                    self.logger.print_warning(f"âš ï¸ {name} å†è©¦è¡Œ ({attempt+1}/{max_retries})")
                    self.perform_aggressive_memory_cleanup()
                    if self.auto_adjust:
                        self.escalate_memory_adjustment()
                    time.sleep(self.recovery_delay)
                    continue
                raise HybridGenerationError(f"{name} ãƒ¡ãƒ¢ãƒªä¸è¶³: {e}")
        raise HybridGenerationError(f"{name} æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°åˆ°é”")
