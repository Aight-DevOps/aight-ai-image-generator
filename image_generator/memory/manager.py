#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MemoryManager - ã‚¦ãƒ«ãƒˆãƒ©ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
- check_memory_usage: VRAM ä½¿ç”¨é‡ç›£è¦–
- perform_aggressive_memory_cleanup: ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- escalate_memory_adjustment: æ®µéšçš„ãƒ¡ãƒ¢ãƒªèª¿æ•´
- execute_with_ultra_memory_safety: ãƒ¡ãƒ¢ãƒªã‚»ãƒ¼ãƒ•å®Ÿè¡Œ
"""

import time
import gc
import torch
from common.logger import ColorLogger

class MemoryManager:
    """ã‚¦ãƒ«ãƒˆãƒ©ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config):
        """
        Args:
            config: è¨­å®š dict
        """
        self.logger = ColorLogger()
        mem_cfg = config.get('memory_management', {})
        self.enabled = mem_cfg.get('enabled', True)
        self.threshold = mem_cfg.get('threshold_percent', 70)
        self.auto_adjust = mem_cfg.get('auto_adjustment_enabled', True)
        self.cleanup_interval = mem_cfg.get('cleanup_interval', 1)

        # ã‚¦ãƒ«ãƒˆãƒ©ã‚»ãƒ¼ãƒ•è¨­å®š
        self.aggressive = True
        self.preemptive = True
        self.ultra_safe = True
        self.max_retries = mem_cfg.get('max_retries', 5)
        self.recovery_delay = mem_cfg.get('memory_recovery_delay', 10)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£åƒåº¦
        self.fallbacks = config.get('fallback_resolutions', [])
        self.level = -1
        # ä¿å­˜ç”¨ã‚ªãƒªã‚¸ãƒŠãƒ«è§£åƒåº¦
        self.original = {
            'width': config.get('sdxl_generation', {}).get('width'),
            'height': config.get('sdxl_generation', {}).get('height')
        }

    def check_memory_usage(self, force_cleanup=False) -> bool:
        """VRAM ä½¿ç”¨é‡ç›£è¦–"""
        if not torch.cuda.is_available() or not self.enabled:
            return True

        try:
            allocated = torch.cuda.memory_allocated() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            percent = (allocated / total) * 100
            self.logger.print_status(f"ğŸ§  VRAMä½¿ç”¨é‡: {allocated:.2f}GB/{total:.2f}GB ({percent:.1f}%)")

            if force_cleanup or percent > self.threshold:
                if force_cleanup:
                    self.perform_aggressive_memory_cleanup()
                else:
                    self.logger.print_warning(f"âš ï¸ VRAM {self.threshold}% è¶…é: {percent:.1f}%")
                    self.perform_aggressive_memory_cleanup()
                    if self.auto_adjust:
                        self.escalate_memory_adjustment()
                return False

            return True
        except Exception as e:
            self.logger.print_error(f"âŒ ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            return True

    def perform_aggressive_memory_cleanup(self):
        """ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            self.logger.print_status("ğŸ§¹ ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
            if torch.cuda.is_available():
                for _ in range(3):
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    time.sleep(1)
            for _ in range(3):
                gc.collect()
                time.sleep(0.5)
            time.sleep(self.recovery_delay)
            self.logger.print_success("âœ… ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        except Exception as e:
            self.logger.print_error(f"âŒ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def escalate_memory_adjustment(self) -> bool:
        """æ®µéšçš„ãƒ¡ãƒ¢ãƒªèª¿æ•´"""
        self.level += 1
        if self.level >= len(self.fallbacks):
            self.logger.print_error("âŒ æœ€å°è§£åƒåº¦åˆ°é”ã€ã“ã‚Œä»¥ä¸Šèª¿æ•´ã§ãã¾ã›ã‚“")
            return False
        fb = self.fallbacks[self.level]
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        # ã“ã“ã§ config ã«é©ç”¨ã™ã‚‹æƒ³å®š
        self.logger.print_warning(f"ğŸ“‰ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£åƒåº¦é©ç”¨: {fb['width']}x{fb['height']}")
        return True

    def execute_with_ultra_memory_safety(self, func, operation_name, max_retries=None):
        """
        ãƒ¡ãƒ¢ãƒªã‚»ãƒ¼ãƒ•å®Ÿè¡Œãƒ©ãƒƒãƒ‘ãƒ¼
        Args:
            func: å®Ÿè¡Œé–¢æ•°
            operation_name: è¡¨ç¤ºç”¨åå‰
        """
        if max_retries is None:
            max_retries = self.max_retries

        for attempt in range(max_retries):
            try:
                if self.ultra_safe:
                    self.logger.print_status(f"ğŸ›¡ï¸ äº‹å‰å®‰å…¨ãƒã‚§ãƒƒã‚¯: {operation_name}")
                    self.check_memory_usage(force_cleanup=True)
                result = func()
                self.perform_aggressive_memory_cleanup()
                return result
            except RuntimeError as e:
                if "CUDA out of memory" in str(e) and attempt < max_retries - 1:
                    self.logger.print_warning(f"âš ï¸ ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼å†è©¦è¡Œ ({attempt+1}/{max_retries})")
                    self.perform_aggressive_memory_cleanup()
                    if self.auto_adjust:
                        self.escalate_memory_adjustment()
                    time.sleep(self.recovery_delay)
                    continue
                raise
        raise HybridGenerationError(f"{operation_name}: ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼æœ€å¤§ãƒªãƒˆãƒ©ã‚¤åˆ°é”")
